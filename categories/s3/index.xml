<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>S3 on Ian Blenke</title>
    <link>http://ian.blenke.com/categories/s3/</link>
    <description>Recent content in S3 on Ian Blenke</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <lastBuildDate>Wed, 05 Nov 2014 14:40:59 -0500</lastBuildDate>
    <atom:link href="http://ian.blenke.com/categories/s3/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Self-standing Ceph/deis-store docker containers</title>
      <link>http://ian.blenke.com/post/2014-11-05-self-standing-ceph-slash-deis-store-docker-containers/</link>
      <pubDate>Wed, 05 Nov 2014 14:40:59 -0500</pubDate>
      
      <guid>http://ian.blenke.com/post/2014-11-05-self-standing-ceph-slash-deis-store-docker-containers/</guid>
      <description>&lt;p&gt;A common challenge for cloud orchestration is simulating or providing an S3 service layer, particularly for development environments.&lt;/p&gt;

&lt;p&gt;As Docker is meant for immutable infrastructure, this poses somewhat of a challenge for production deployments. Rather than tackle that subject here, we&amp;rsquo;ll revisit persistence on immutable infrastructure in a production capacity in a future blog post.&lt;/p&gt;

&lt;p&gt;The first challenge is identifying an S3 implementation to throw into a container.&lt;/p&gt;

&lt;p&gt;There are a few feature sparse/dummy solutions that might suit development needs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://s3ninja.net/&#34;&gt;s3-ninja&lt;/a&gt; (github &lt;a href=&#34;https://github.com/scireum/s3ninja&#34;&gt;scireum/s3ninja&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/jubos/fake-s3&#34;&gt;fake-s3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sourceforge.net/projects/s3mockup/&#34;&gt;S3Mockup&lt;/a&gt;
(and a number of others which I&amp;rsquo;d rather not even consider)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are a number of good functional options for actual S3 implementations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ceph.com&#34;&gt;ceph&lt;/a&gt; (github &lt;a href=&#34;https://github.com/ceph/ceph&#34;&gt;ceph/ceph&lt;/a&gt;), specifically the &lt;a href=&#34;http://ceph.com/docs/master/radosgw/&#34;&gt;radosgw&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/eucalyptus/eucalyptus/wiki/Walrus-S3-API&#34;&gt;walrus&lt;/a&gt; from Eucalyptus&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://basho.com/riak-cloud-storage/&#34;&gt;riak cs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.skylable.com/download/#LibreS3&#34;&gt;libres3&lt;/a&gt;, backended by the opensource &lt;a href=&#34;http://www.skylable.com/download/#SX&#34;&gt;Skylable Sx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/nimbusproject/nimbus/tree/master/cumulus&#34;&gt;cumulus&lt;/a&gt; is an S3 implementation for &lt;a href=&#34;http://www.nimbusproject.org/docs/current/faq.html#cumulus&#34;&gt;Nimbus&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cloudian.com/community-edition.php&#34;&gt;cloudian&lt;/a&gt; which is a non-opensource commercial product&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/stackforge/swift3&#34;&gt;swift3&lt;/a&gt; as an S3 compatibility layer with swift on the backend&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudfoundry-attic/vblob&#34;&gt;vblob&lt;/a&gt; a node.js based attic&amp;rsquo;ed project at CloudFoundry&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/mattjamieson/parkplace&#34;&gt;parkplace&lt;/a&gt; backended by bittorrent&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/razerbeans/boardwalk&#34;&gt;boardwalk&lt;/a&gt; backended by ruby, sinatra, and mongodb&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Of the above, one stands out as the underlying persistence engine used by a larger docker backended project: &lt;a href=&#34;http://deis.io&#34;&gt;Deis&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Rather than re-invent the wheel, it is possible to use deis-store directly.&lt;/p&gt;

&lt;p&gt;As Deis deploys on CoreOS, there is an understandable inherent dependency on &lt;a href=&#34;http://github.com/coreos/etcd/&#34;&gt;etcd&lt;/a&gt; for service discovery.&lt;/p&gt;

&lt;p&gt;If you happen to be targeting CoreOS, you can simply point your etcd &amp;ndash;peers option or &lt;code&gt;ETCD_HOST&lt;/code&gt; environment variable at &lt;code&gt;$COREOS_PRIVATE_IPV4&lt;/code&gt; and skip this next step.&lt;/p&gt;

&lt;p&gt;First, make sure your environment includes the &lt;code&gt;DOCKER_HOST&lt;/code&gt; and related variables for the boot2docker environment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;eval $(boot2docker shellinit)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, discover the IP of the boot2docker guest VM, as that is what we will bind the etcd to:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;IP=&amp;quot;$(boot2docker ip 2&amp;gt;/dev/null)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next, we can spawn etcd and publish the ports for the other containers to use:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --name etcd \
           --publish 4001:4001 \
           --publish 7001:7001 \
           --detach \
           coreos/etcd:latest \
           /go/bin/app -listen-client-urls http://0.0.0.0:4001 \
                       -advertise-client-urls http://$IP:4001 \
                       -listen-peer-urls http://0.0.0.0:7001 \
                       -initial-advertise-peer-urls http://$IP:7001 \
                       -data-dir=/tmp/etcd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Normally, we wouldn&amp;rsquo;t put the etcd persistence in a tmpfs for consistency reasons after a reboot, but for a development container: we love speed!&lt;/p&gt;

&lt;p&gt;Now that we have an etcd container running, we can spawn the deis-store daemon container that runs the ceph object-store daemon (OSD) module.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --name deis-store-daemon \
           --volumes-from=deis-store-daemon-data \
           --env HOST=$IP \
           --publish 6800 \
           --net host \
           --detach \
           deis/store-daemon:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It is probably a good idea to mount the /var/lib/deis/store volume for persistence, but this is a developer container, so we&amp;rsquo;ll forego that step.&lt;/p&gt;

&lt;p&gt;The ceph-osd will wait in a loop when starting until it can talk to ceph-mon, which is the next component provided by the deis-store monitor container.&lt;/p&gt;

&lt;p&gt;In order to prepare the etcd config tree for deis-store monitor, we must first set a key for this new deis-store-daemon component.&lt;/p&gt;

&lt;p&gt;While we could do that with a wget/curl PUT to the etcd client port (4001), using etcdctl makes things a bit easier.&lt;/p&gt;

&lt;p&gt;It is generally a good idea to match the version of the etcdctl client with the version of etcd you are using.&lt;/p&gt;

&lt;p&gt;As the CoreOS team doesn&amp;rsquo;t put out an etcdctl container as of yet, one way to do this is to build/install etcdctl inside a coreos/etcd container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --rm \
           coreos/etcd \
           /bin/sh -c &amp;quot;cd /go/src/github.com/coreos/etcd/etcdctl; \
                       go install ; \
                       /go/bin/etcdctl --peers $IP:4001 \
                       set /deis/store/hosts/$IP $IP&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This isn&amp;rsquo;t ideal, of course, as there is a slight delay as etcdctl is built and installed before we use it, but it serves the purpose.&lt;/p&gt;

&lt;p&gt;There are also &lt;a href=&#34;http://docs.deis.io/en/latest/managing_deis/store_daemon_settings/&#34;&gt;deis/store-daemon settings&lt;/a&gt; of etcd keys that customize the behavior of ceph-osd a bit.&lt;/p&gt;

&lt;p&gt;Now we can start deis-store-monitor, which will use that key to spin up a ceph-mon that monitors this (and any other) ceph-osd instances likewise registered in the etcd configuration tree.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --name deis-store-monitor \
           --env HOST=$IP \
           --publish 6789 \
           --net host \
           --detach \
           deis/store-monitor:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As before, there are volumes that probably should be mounted for /etc/ceph and /var/lib/ceph/mon, but this is a development image, so we&amp;rsquo;ll skip that.&lt;/p&gt;

&lt;p&gt;There are also &lt;a href=&#34;http://docs.deis.io/en/latest/managing_deis/store_monitor_settings/&#34;&gt;deis/store-monitor settings&lt;/a&gt; of etcd keys that customize the behavior of ceph-mon a bit.&lt;/p&gt;

&lt;p&gt;Now that ceph-mon is running, ceph-osd will continue starting up. We now have a single-node self-standing ceph storage platform, but no S3.&lt;/p&gt;

&lt;p&gt;The S3 functionality is provided by the ceph-radosgw component, which is provided by the deis-store-gateway container.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run --name deis-store-gateway \
           --hostname deis-store-gateway \
           --env HOST=$IP \
           --env EXTERNAL_PORT=8888 \
           --publish 8888:8888 \
           --detach \
           deis/store-gateway:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is no persistence in ceph-radosgw that warrant a volume mapping, so we can ignore that entirely regardless of environment.&lt;/p&gt;

&lt;p&gt;There are also &lt;a href=&#34;http://docs.deis.io/en/latest/managing_deis/store_gateway_settings/&#34;&gt;deis/store-gateway settings&lt;/a&gt; of etcd keys that customize the behavior of ceph-radosgw a bit.&lt;/p&gt;

&lt;p&gt;We now have a functional self-standing S3 gateway, but we don&amp;rsquo;t know the credentials to use it. For that, we can run etcdctl again:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AWS_ACCESS_KEY_ID=$(docker run --rm coreos/etcd /bin/sh -c &amp;quot;cd /go/src/github.com/coreos/etcd/etcdctl; go install ; /go/bin/etcdctl --peers $IP:4001 get /deis/store/gateway/accessKey&amp;quot;)
AWS_SECRET_ACCESS_KEY=$(docker run --rm coreos/etcd /bin/sh -c &amp;quot;cd /go/src/github.com/coreos/etcd/etcdctl; go install ; /go/bin/etcdctl --peers $IP:4001 get /deis/store/gateway/secretKey&amp;quot;)
AWS_S3_HOST=$(docker run --rm coreos/etcd /bin/sh -c &amp;quot;cd /go/src/github.com/coreos/etcd/etcdctl; go install ; /go/bin/etcdctl --peers $IP:4001 get /deis/store/gateway/host&amp;quot;)
AWS_S3_PORT=$(docker run --rm coreos/etcd /bin/sh -c &amp;quot;cd /go/src/github.com/coreos/etcd/etcdctl; go install ; /go/bin/etcdctl --peers $IP:4001 get /deis/store/gateway/port&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the host here isn&amp;rsquo;t the normal AWS gateway address, so you will need to specify things for your S3 client to access it correctly.&lt;/p&gt;

&lt;p&gt;Likewise, you may need to specify an URL scheme of &amp;ldquo;http&amp;rdquo;, as the above does not expose an HTTPS encrypted port.&lt;/p&gt;

&lt;p&gt;There are also S3 client changes that &lt;a href=&#34;https://github.com/deis/deis/issues/2326&#34;&gt;may be necessary&lt;/a&gt; depending on the &amp;ldquo;calling format&amp;rdquo; of the client libraries. You may need to &lt;a href=&#34;http://stackoverflow.com/questions/24312350/using-paperclip-fog-and-ceph&#34;&gt;changes things like paperclip&lt;/a&gt; to &lt;a href=&#34;https://github.com/thoughtbot/paperclip/issues/1577&#34;&gt;work with fog&lt;/a&gt;. There are numerous tools that work happily with ceph, like &lt;a href=&#34;https://github.com/stiller/s3_to_ceph/blob/master/s3_to_ceph.rb&#34;&gt;s3_to_ceph&lt;/a&gt; and even gems like &lt;a href=&#34;https://github.com/fog/fog-radosgw&#34;&gt;fog-radosgw&lt;/a&gt; that try and help make this painless for your apps.&lt;/p&gt;

&lt;p&gt;I will update this blog post shortly with an example of a containerized s3 client to show how to prove your ceph radosgw is working.&lt;/p&gt;

&lt;p&gt;Have fun!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>